{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#pre_processing libraries\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stopwords=stopwords.words('english')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "import nltk\n",
    "import ast\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag, pos_tag_sents,RegexpParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skills', 'description'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('sample_jobs_data.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['title','jobFunction','industry','requirements'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(471, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take sample from data\n",
    "#df=df.sample(n = 600).reset_index(drop=True)\n",
    "#df=df[:500]\n",
    "#save df as csv\n",
    "#df.to_csv('new_sample_jobs_data.csv', index = False, header=True)\n",
    "#delete nan values\n",
    "df=df[df['description'] != \"NaN\"]\n",
    "df=df.dropna()\n",
    "# delete duplicated rows\n",
    "df=df.drop_duplicates(subset =\"description\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description']=[sent_tokenize(re.sub(r'[|]', ' ', row)) for row in df['description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POS\n",
    "tagged_texts=[]\n",
    "desc_sent=[]\n",
    "for row in df['description']:\n",
    "    #for sent in sent_tokenize(row):\n",
    "    for sent in row:\n",
    "        desc_sent.append(sent)\n",
    "        tagged_texts.append(pos_tag(sent.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunking NPs\n",
    "NPs=[]\n",
    "grammar = \"NP: {<NN>*|<NN>*<NNs>*|<NNs>*|<NNs>*<VBG>|<NN>*<VBG>|<VBG>|<NNP>*}\"\n",
    "cp  = RegexpParser(grammar)\n",
    "for x in tagged_texts:\n",
    "    NPs.append([' '.join([c[0] for c in chunk]) for chunk in cp.parse(x) if type(chunk) == nltk.tree.Tree]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills are str. ast convert string to list\n",
    "df['skills']=[ast.literal_eval(y) for y in df['skills']]\n",
    "\n",
    "#append all skills in a list\n",
    "skills=[]\n",
    "for x in df['skills']:\n",
    "    for y in x:\n",
    "        skills.append(y)\n",
    "        \n",
    "#unique skills      \n",
    "u_skills=(np.unique(np.array(skills)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(row):\n",
    "    r = [ \" \".join(lemma.lemmatize(word.strip()) for word in s.split()\n",
    "                        if word not in stopwords ) and re.sub(r'[^\\w]', ' ', s.lower().strip())  for s in row ]\n",
    "    \n",
    "    return r\n",
    "\n",
    "u_skills= clean(u_skills)\n",
    "NPs=[clean(row) for row in NPs]\n",
    "desc_sent=clean(desc_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NPs</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[math, create lesson, assign, homework  manage...</td>\n",
       "      <td>math teachers actively instruct students  crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[accordance, principles , students , locations ]</td>\n",
       "      <td>deliver lessons in accordance with berlitz tea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[evaluation, progress]</td>\n",
       "      <td>provide evaluation for progress reports and ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[feedback, advice , product]</td>\n",
       "      <td>provide effective feedback and advice  recomme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[customer focus, delivery, duties ]</td>\n",
       "      <td>maintain an impeccable customer focus in the d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 NPs  \\\n",
       "0  [math, create lesson, assign, homework  manage...   \n",
       "1   [accordance, principles , students , locations ]   \n",
       "2                             [evaluation, progress]   \n",
       "3                       [feedback, advice , product]   \n",
       "4                [customer focus, delivery, duties ]   \n",
       "\n",
       "                                         description  \n",
       "0  math teachers actively instruct students  crea...  \n",
       "1  deliver lessons in accordance with berlitz tea...  \n",
       "2  provide evaluation for progress reports and ce...  \n",
       "3  provide effective feedback and advice  recomme...  \n",
       "4  maintain an impeccable customer focus in the d...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({\"NPs\": NPs,\"description\" :desc_sent})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build context list with (neighbour words)n=4 for skill NPs\n",
    "phrase=[]\n",
    "context=[]\n",
    "skill_notskill=[]\n",
    "phrase_and_context=[]\n",
    "for i in range(0,data.shape[0]) :\n",
    "    for NP in data.NPs.iloc[i]:\n",
    "        phrase.append(NP.strip())\n",
    "        if NP in u_skills:\n",
    "            skill_notskill.append(1)\n",
    "        else:\n",
    "            skill_notskill.append(0)\n",
    "            \n",
    "        m = re.search(r'((?:\\w+\\W+){,3})('+ NP.strip() +')\\W+((?:\\w+\\W+){,3})',data.description.iloc[i]+\".\")\n",
    "        if m:\n",
    "            l = [ x.strip().split() for x in m.groups() ]\n",
    "            context.append( l[0] + l[2])\n",
    "            phrase_and_context.append(l[0] +l[1] +l[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>context</th>\n",
       "      <th>phrase_and_context</th>\n",
       "      <th>skill_notskill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>math</td>\n",
       "      <td>[teachers, actively, instruct]</td>\n",
       "      <td>[math, teachers, actively, instruct]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>create lesson</td>\n",
       "      <td>[actively, instruct, students, plans, assign, ...</td>\n",
       "      <td>[actively, instruct, students, create, lesson,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>assign</td>\n",
       "      <td>[create, lesson, plans, and, correct, homework]</td>\n",
       "      <td>[create, lesson, plans, assign, and, correct, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>homework  manage</td>\n",
       "      <td>[assign, and, correct, students, in, the]</td>\n",
       "      <td>[assign, and, correct, homework, manage, stude...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>classroom  communicate</td>\n",
       "      <td>[students, in, the, with, parents, and]</td>\n",
       "      <td>[students, in, the, classroom, communicate, wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   phrase                                            context  \\\n",
       "0                    math                     [teachers, actively, instruct]   \n",
       "1           create lesson  [actively, instruct, students, plans, assign, ...   \n",
       "2                  assign    [create, lesson, plans, and, correct, homework]   \n",
       "3        homework  manage          [assign, and, correct, students, in, the]   \n",
       "4  classroom  communicate            [students, in, the, with, parents, and]   \n",
       "\n",
       "                                  phrase_and_context  skill_notskill  \n",
       "0               [math, teachers, actively, instruct]               1  \n",
       "1  [actively, instruct, students, create, lesson,...               0  \n",
       "2  [create, lesson, plans, assign, and, correct, ...               0  \n",
       "3  [assign, and, correct, homework, manage, stude...               0  \n",
       "4  [students, in, the, classroom, communicate, wi...               0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'phrase':phrase, 'context':context ,'phrase_and_context':phrase_and_context ,'skill_notskill':skill_notskill } \n",
    "data = pd.DataFrame(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('clean_data.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>context</th>\n",
       "      <th>phrase_and_context</th>\n",
       "      <th>skill_notskill</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8384</th>\n",
       "      <td>setup</td>\n",
       "      <td>['system', 'installation', 'and', 'and', 'cust...</td>\n",
       "      <td>['system', 'installation', 'and', 'setup', 'an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8385</th>\n",
       "      <td>business</td>\n",
       "      <td>['customize', 'them', 'for', 'needs', 'run', '...</td>\n",
       "      <td>['customize', 'them', 'for', 'business', 'need...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8386</th>\n",
       "      <td>system  train end</td>\n",
       "      <td>['run', 'tests', 'on', 'users', 'and', 'write']</td>\n",
       "      <td>['run', 'tests', 'on', 'system', 'train', 'end...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8387</th>\n",
       "      <td>instruction</td>\n",
       "      <td>['users', 'and', 'write', 'manuals', 'as', 'ne...</td>\n",
       "      <td>['users', 'and', 'write', 'instruction', 'manu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8388</th>\n",
       "      <td>necessary</td>\n",
       "      <td>['instruction', 'manuals', 'as']</td>\n",
       "      <td>['instruction', 'manuals', 'as', 'necessary']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 phrase                                            context  \\\n",
       "8384              setup  ['system', 'installation', 'and', 'and', 'cust...   \n",
       "8385           business  ['customize', 'them', 'for', 'needs', 'run', '...   \n",
       "8386  system  train end    ['run', 'tests', 'on', 'users', 'and', 'write']   \n",
       "8387        instruction  ['users', 'and', 'write', 'manuals', 'as', 'ne...   \n",
       "8388          necessary                   ['instruction', 'manuals', 'as']   \n",
       "\n",
       "                                     phrase_and_context  skill_notskill  \n",
       "8384  ['system', 'installation', 'and', 'setup', 'an...               0  \n",
       "8385  ['customize', 'them', 'for', 'business', 'need...               1  \n",
       "8386  ['run', 'tests', 'on', 'system', 'train', 'end...               0  \n",
       "8387  ['users', 'and', 'write', 'instruction', 'manu...               0  \n",
       "8388      ['instruction', 'manuals', 'as', 'necessary']               0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('clean_data.csv')\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating words Embedding for NPs, Context and NPs + Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Feature Engineering with word embedding\n",
    "# Extract word vectors\n",
    "word_embeddings = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    word_embeddings[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "# prepare embedding matrix \n",
    "from keras.layers import Embedding\n",
    "from keras.initializers import Constant\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 50 #max number of words in sentence\n",
    "MAX_NUM_WORDS = 1000  # max number of words in vocablary\n",
    "VALIDATION_SPLIT = 0.2 #ratio to split data\n",
    "EMBEDDING_DIM = word_embeddings.get('a').shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take list of lists text data return Embedding layer for it\n",
    "def pad_sequences_data(texts):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    word_index = tokenizer.word_index\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    return word_index, data\n",
    "\n",
    "def get_emb_layer(texts):\n",
    "    word_index = pad_sequences_data(texts)[0]\n",
    "    #Get Embedding vector for each word from pretraind word Embeddings(Glove)\n",
    "    num_words =len(word_index) + 1\n",
    "    emb_matrix = np.zeros((num_words , EMBEDDING_DIM))\n",
    "    for word, i in word_index.items():\n",
    "        if i > num_words:\n",
    "            continue\n",
    "        embedding_vector = word_embeddings.get(word) ## This references the loaded embeddings dictionary\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            emb_matrix[i] = embedding_vector\n",
    "            \n",
    "    # load pre-trained word embeddings into an Embedding layer\n",
    "    # note that we set trainable = False so as to keep the embeddings fixed\n",
    "    emb_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(emb_matrix),\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)\n",
    "    \n",
    "    return emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Embedding layer for context\n",
    "#convert str to list\n",
    "data.context=[ast.literal_eval(x) for x in data.context]\n",
    "cont_text=data.context.values.tolist()\n",
    "cont_emb_layer=get_emb_layer(cont_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding layer for phrase_and_context\n",
    "#convert str to list\n",
    "data.phrase_and_context=[ast.literal_eval(x) for x in data.phrase_and_context]\n",
    "phrase_cont_text=data.phrase_and_context.values.tolist()\n",
    "\n",
    "emb_layer_dense=get_emb_layer(phrase_cont_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embedding layer for phrase\n",
    "ph_text=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    ph_text.append(str(data.phrase.iloc[i]).strip().split())\n",
    "    \n",
    "phrase_emb_layer=get_emb_layer(ph_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "def build_model():\n",
    "    lstm_input_phrase = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    lstm_input_cont = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "    dense_input = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "    emb_phrase = phrase_emb_layer(lstm_input_phrase)\n",
    "    lstm_emb_phrase = keras.layers.LSTM(256)(emb_phrase)\n",
    "    lstm_emb_phrase = keras.layers.Dense(128, activation='relu')(lstm_emb_phrase)\n",
    "\n",
    "    emb_cont = cont_emb_layer(lstm_input_cont)\n",
    "    lstm_emb_cont = keras.layers.LSTM(256)(emb_cont)\n",
    "    lstm_emb_cont = keras.layers.Dense(128, activation='relu')(lstm_emb_cont)\n",
    "\n",
    "    dense_emb  = emb_layer_dense(dense_input)\n",
    "    dense_emb = keras.layers.Dense(512, activation='relu')(dense_input)\n",
    "    dense_emb = keras.layers.Dense(256, activation='relu')(dense_emb)\n",
    "\n",
    "    keras.layers.concatenate([lstm_emb_phrase, lstm_emb_cont, dense_emb])\n",
    "\n",
    "    x = keras.layers.concatenate([lstm_emb_phrase, lstm_emb_cont, dense_emb])\n",
    "    x = keras.layers.Dense(128, activation='relu')(x)\n",
    "    x = keras.layers.Dense(64, activation='relu')(x)\n",
    "    x = keras.layers.Dense(32, activation='relu')(x)\n",
    "\n",
    "    main_output = keras.layers.Dense(2, activation='softplus')(x)\n",
    "\n",
    "    model = keras.models.Model(inputs=[lstm_input_phrase, lstm_input_cont, dense_input],\n",
    "                                    outputs=main_output)\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "\n",
    "    return model\n",
    "    \n",
    "'''onehot_transformfunction \n",
    "   converts the target values 0 and 1 to one-hot vectors [1,0] and [0,1]'''\n",
    "\n",
    "def onehot_transform(y):\n",
    "\n",
    "    onehot_y = []\n",
    "\n",
    "    for numb in y:\n",
    "        onehot_arr = np.zeros(2)\n",
    "        onehot_arr[numb] = 1\n",
    "        onehot_y.append(np.array(onehot_arr))\n",
    "\n",
    "    return np.array(onehot_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#fit the model\n",
    "def fit( x_lstm_phrase, x_lstm_context, x_dense, y,\n",
    "            val_split=0.25, patience=5, max_epochs=1000, batch_size=32):\n",
    "    \n",
    "        x_lstm_phrase_seq = pad_sequences_data(x_lstm_phrase)[1]\n",
    "        x_lstm_context_seq = pad_sequences_data(x_lstm_context)[1]\n",
    "        x_dense_seq=pad_sequences_data(x_dense)[1]\n",
    "        y_onehot=onehot_transform(y)\n",
    "        model.fit([x_lstm_phrase_seq, x_lstm_context_seq, x_dense_seq] ,y_onehot,\n",
    "                   batch_size=batch_size,\n",
    "                   epochs = max_epochs ,\n",
    "                   validation_split=val_split,\n",
    "                   callbacks=[keras.callbacks.EarlyStopping\n",
    "                              (monitor='val_loss', patience=patience)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 6291 samples, validate on 2098 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\DINA\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "6291/6291 [==============================] - 60s 9ms/step - loss: 2.1875 - val_loss: 2.1636\n",
      "Epoch 2/1000\n",
      "6291/6291 [==============================] - 55s 9ms/step - loss: 1.7614 - val_loss: 1.8722\n",
      "Epoch 3/1000\n",
      "6291/6291 [==============================] - 59s 9ms/step - loss: 1.8003 - val_loss: 2.3835\n",
      "Epoch 4/1000\n",
      "6291/6291 [==============================] - 60s 9ms/step - loss: 1.7219 - val_loss: 1.5090\n",
      "Epoch 5/1000\n",
      "6291/6291 [==============================] - 61s 10ms/step - loss: 1.4522 - val_loss: 1.4214\n",
      "Epoch 6/1000\n",
      "6291/6291 [==============================] - 65s 10ms/step - loss: 1.5308 - val_loss: 1.5560\n",
      "Epoch 7/1000\n",
      "6291/6291 [==============================] - 67s 11ms/step - loss: 1.6163 - val_loss: 2.0305\n",
      "Epoch 8/1000\n",
      "6291/6291 [==============================] - 69s 11ms/step - loss: 1.7029 - val_loss: 1.5452\n",
      "Epoch 9/1000\n",
      "6291/6291 [==============================] - 75s 12ms/step - loss: 1.6955 - val_loss: 1.8065\n",
      "Epoch 10/1000\n",
      "6291/6291 [==============================] - 76s 12ms/step - loss: 1.5792 - val_loss: 1.5377\n"
     ]
    }
   ],
   "source": [
    "model= build_model()\n",
    "fit(ph_text,cont_text,phrase_cont_text,data['skill_notskill'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
